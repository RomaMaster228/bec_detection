{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Обнаружение событий, связанных с копроментацией корпоративной электронной почты, в процессе мониторинга исходящей корреспонденции на основе методов машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Подготовка датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Используем [открьтый датасет компании Enron](https://www.cs.cmu.edu/~enron/). Разархивируем его и превратим его в нужные нам датасеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mailparser\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Как выглядит типичное письмо из данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"enron_mail_20150507/maildir/delainey-d/sent/1.\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Письма раскиданы по папкам. Берём все папки, в которых встречается слово sent - папки с исходящей корреспонденцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deleted_items', 'discussion_threads', 'sent', 'notes_inbox', '_sent_mail', 'sent_items', 'all_documents', 'inbox']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"enron_mail_20150507/maildir/delainey-d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_emails_by_sender(path=\"enron_mail_20150507\"):\n",
    "    outgoing_emails_by_user = {}\n",
    "    unsuccessful = 0\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    total_emails = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Обрабатываем только отправленные сообщения\n",
    "        if not (\"sent\" in root):\n",
    "            continue\n",
    "\n",
    "        for file_name in files:\n",
    "            try:\n",
    "                msg = mailparser.parse_from_file(os.path.join(root, file_name))\n",
    "                sender = msg.headers.get(\"From\")\n",
    "                body = msg.body\n",
    "\n",
    "                if sender:\n",
    "                    sender = re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', sender)\n",
    "                    if sender:\n",
    "                        sender = sender.group().lower()\n",
    "                        if sender not in outgoing_emails_by_user:\n",
    "                            outgoing_emails_by_user[sender] = set()\n",
    "                        outgoing_emails_by_user[sender].add(body)\n",
    "                        total_emails += 1\n",
    "            except Exception:\n",
    "                unsuccessful += 1\n",
    "\n",
    "    print(f\"Total unsuccessful: {unsuccessful}/{total_emails}\")\n",
    "    return outgoing_emails_by_user\n",
    "\n",
    "\n",
    "def extract_reply_from_email(text: str, sender_email: str):\n",
    "    i = text.find(\"\\n\\n\\n\")\n",
    "    if i != -1:\n",
    "        text = text[:i]\n",
    "    i = text.find(\"----- Forwarded\")\n",
    "    if i != -1:\n",
    "        text = text[:i]\n",
    "    i = text.find(\"Original Message\")\n",
    "    if i != -1:\n",
    "        text = text[:i]\n",
    "    text = re.sub(\"-{3,50}\", \"\", text)\n",
    "    name = sender_email.split(\"@\")[0].split(\".\")\n",
    "    if name:\n",
    "        if len(name) > 1:\n",
    "            r = re.compile(re.escape(name[1]), re.IGNORECASE)\n",
    "            text = r.sub(\"\", text)\n",
    "        if len(name[0]) > 2:\n",
    "            r = re.compile(re.escape(name[0]), re.IGNORECASE)\n",
    "            text = r.sub(\"\", text)\n",
    "    text = text.rstrip(\" \\n\")\n",
    "    text = re.sub(r'(\\n\\n.{3,50})$', '', text)\n",
    "    text = re.sub(\"thanks.?\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"(\\w{3,10}[,:](\\n|\\n\\n)|^\\w{3,10}[,:]|\\n\\w{3,10}[,:])\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "emails_dict = parse_emails_by_sender(path=\"enron_mail_20150507\")\n",
    "skip_emails = {\"no.address@enron.com\", \"40enron@enron.com\"}\n",
    "senders, emails = [], []\n",
    "for sender, emails_ in zip(emails_dict.keys(), emails_dict.values()):\n",
    "    if sender not in skip_emails:\n",
    "        unique_emails = set()\n",
    "        for email in emails_:\n",
    "            email = extract_reply_from_email(email, sender)\n",
    "            if len(email) > 10 and \"Outlook Migration Team\" not in email:\n",
    "                unique_emails.add(email)\n",
    "        for email in unique_emails:\n",
    "            senders.append(sender)\n",
    "            emails.append(email)\n",
    "df = pd.DataFrame(list(zip(senders, emails)), columns=['sender', 'text'])\n",
    "df.to_csv(\"raw_emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_emails.csv')\n",
    "# print(df[\"sender\"].value_counts())  # Люди с максимальным и минимальным числом писем\n",
    "d = df.to_dict()\n",
    "senders = list(d[\"sender\"].values())\n",
    "texts = list(d[\"text\"].values())\n",
    "datasets = dict()\n",
    "for i, sender in enumerate(senders):\n",
    "    if sender in datasets:\n",
    "        datasets[sender].append([texts[i], 1])\n",
    "    else:\n",
    "        datasets[sender] = [[texts[i], 1]]\n",
    "numbers_of_owned_emails = {sender: len(datasets[sender]) for sender in datasets}\n",
    "for sender in datasets:\n",
    "    other_texts = []\n",
    "    for i, text in enumerate(texts):\n",
    "        if sender != senders[i]:\n",
    "            other_texts.append(text)\n",
    "    for _ in range(numbers_of_owned_emails[sender]):\n",
    "        datasets[sender].append([random.choice(other_texts), 0])\n",
    "if not os.path.exists(\"datasets\"):\n",
    "    os.mkdir(\"datasets\")\n",
    "for sender in datasets:\n",
    "    df = pd.DataFrame(list(zip([row[0] for row in datasets[sender]],\n",
    "                               [row[1] for row in datasets[sender]])),\n",
    "                      columns=['text', 'label'])\n",
    "    df.to_csv(os.path.join(\"datasets\", f\"{sender.split('@')[0].replace('.', '_')}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "В итоге, получаем папку datasets с датасетом для каждого работника компании, в котором размечены письма (письма от этого человека - 1, другие письма - 0). Другие письма выбираются случайным образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"datasets\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Самые распространенные слова в сообщениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words_stat = dict()\n",
    "for dataset in os.listdir(\"datasets\"):\n",
    "    df = pd.read_csv(f\"datasets/{dataset}\")\n",
    "    for text in df[\"text\"].values:\n",
    "        for pair in Counter(text.replace('\\n', '').split()).most_common(100):\n",
    "            if pair[0] in words_stat:\n",
    "                words_stat[pair[0]] += pair[1]\n",
    "            else:\n",
    "                words_stat[pair[0]] = pair[1]\n",
    "print(sorted(words_stat.items(), key=lambda x:x[1], reverse=True)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Выбор датасетов для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Выберем 5 человек, у которых больше всего исходящих писем и отсутствуют подписи к письмам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "chosen_datasets = ['kate_symes.csv', 'sally_beck.csv', 'carol_clair.csv', 'michelle_cash.csv', 'chris_germany.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for dataset in chosen_datasets:\n",
    "    print(pd.read_csv(f\"datasets/{dataset}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "precision_recall_curve, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Будем использовать 2 способа векторизации текстов - TF-IDF и CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(df: pd.DataFrame):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    return np.array(tfidf.fit_transform(df['text']).todense())\n",
    "\n",
    "\n",
    "def vectorize(df: pd.DataFrame):\n",
    "    count_vec = CountVectorizer()\n",
    "    return np.array(count_vec.fit_transform(df['text']).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Определяем класс для обучения и тестирования моделей. Обучающая выборка - 70% датасета. to_vec_func - выбранный способ векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "\n",
    "    def __init__(self, csv_path, train_dir_path):\n",
    "        self.dataset = pd.read_csv(os.path.join(\"datasets\", csv_path))\n",
    "        self.dataset_name = csv_path.split(\".\")[0]\n",
    "        self.train_info = {}\n",
    "        self.train_dir_path = train_dir_path\n",
    "\n",
    "    def update_train_info(self, info, model_name, vec_name):\n",
    "        if model_name in self.train_info:\n",
    "            self.train_info[model_name][vec_name] = info\n",
    "        else:\n",
    "            self.train_info[model_name] = {vec_name: info}\n",
    "\n",
    "    def save_train_info_into_pickle(self):\n",
    "        if not os.path.exists(self.train_dir_path):\n",
    "            os.mkdir(self.train_dir_path)\n",
    "        with open(os.path.join(self.train_dir_path, f\"{self.dataset_name}.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(self.train_info, f)\n",
    "\n",
    "    def count_acc(self, pred_scores, scores):\n",
    "        correct = 0\n",
    "        res_acc = []\n",
    "        pred_scores = list(pred_scores)\n",
    "        scores = list(scores)\n",
    "        for i in range(len(scores)):\n",
    "            if pred_scores[i] == scores[i]:\n",
    "                correct += 1\n",
    "            res_acc.append(correct / (i + 1))\n",
    "        return res_acc\n",
    "\n",
    "    def plot_accuracy(self, train_pred_scores, train_scores, test_pred_scores, test_scores):\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.title('Accuracy')\n",
    "        plt.xticks([])\n",
    "        plt.plot(self.count_acc(train_pred_scores, train_scores), color='r', label=\"Train\")\n",
    "        plt.plot(self.count_acc(test_pred_scores, test_scores), color='b', label=\"Test\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_precision_recall_curve(self, y_test, y_pred):\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Presicion')\n",
    "        plt.title('Precision-recall curve')\n",
    "        plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.grid()\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, conf_matrix):\n",
    "        cm = ConfusionMatrixDisplay(conf_matrix)\n",
    "        cm.plot()\n",
    "        plt.show()\n",
    "\n",
    "    def train(self, model, to_vec_func):\n",
    "        model_name = model.__class__.__name__\n",
    "        X = to_vec_func(self.dataset)\n",
    "        y = self.dataset[\"label\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "        model = model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        self.plot_accuracy(y_train_pred, y_train, y_pred, y_test)\n",
    "        self.plot_precision_recall_curve(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        self.plot_confusion_matrix(conf_matrix)\n",
    "        self.update_train_info({\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1 score': f1_score(y_test, y_pred, average=\"macro\"),\n",
    "            'Confusion matrix': conf_matrix\n",
    "        }, model_name, to_vec_func.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models = [MultinomialNB, LogisticRegression, SVC, KNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier]\n",
    "for dataset in chosen_datasets:\n",
    "    model_trainer = ModelTrainer(dataset, train_dir_path=\"train\")\n",
    "    print(f\"Start processing {dataset}\")\n",
    "    for i, model in enumerate(models):\n",
    "        model_trainer.train(model(), vectorize)\n",
    "        model_trainer.train(model(), tfidf)\n",
    "        print(f\"Processed model {i + 1}/{len(models)}\")\n",
    "    model_trainer.save_train_info_into_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def analyze_train_data(dir_path):\n",
    "    res_data = {}\n",
    "    for train_data in os.listdir(dir_path):\n",
    "        with open(os.path.join(dir_path, train_data), 'rb') as f:\n",
    "            d = pickle.load(f)\n",
    "            for name in d:\n",
    "                if name not in res_data:\n",
    "                    res_data[name] = {'vectorize': {}, 'tfidf': {}}\n",
    "                    for vec_name in d[name]:\n",
    "                        for key in d[name][vec_name]:\n",
    "                            res_data[name][vec_name][key] = [d[name][vec_name][key]]\n",
    "                else:\n",
    "                    for vec_name in d[name]:\n",
    "                        for key in d[name][vec_name]:\n",
    "                            res_data[name][vec_name][key].append(d[name][vec_name][key])\n",
    "    tmp = copy.deepcopy(res_data)\n",
    "    max_score = 0\n",
    "    model_name = \"\"\n",
    "    for m in tmp:\n",
    "        for vec_name in tmp[m]:\n",
    "            for key in tmp[m][vec_name]:\n",
    "                if key != \"Confusion matrix\":\n",
    "                    res_data[m][vec_name][key] = np.average(res_data[m][vec_name][key])\n",
    "                    if key == \"Accuracy\" and res_data[m][vec_name][key] > max_score:\n",
    "                        max_score = res_data[m][vec_name][key]\n",
    "                        model_name = m\n",
    "                else:\n",
    "                    res_data[m][vec_name].pop(\"Confusion matrix\")\n",
    "    print(res_data)\n",
    "    print(f\"Best accuracy: {max_score}\")\n",
    "    print(f\"Best model: {model_name}\")\n",
    "\n",
    "\n",
    "analyze_train_data(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Препроцессинг текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans(punctuation, ' ' * len(punctuation))\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'{[^>]+}', ' ', text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', ' ', text)\n",
    "    text = re.sub(r'[0-9]+', ' ', text)\n",
    "    text = re.sub(r'-|«|»', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.strip()\n",
    "    # text = ' '.join([word for i, word in enumerate(text.split()) if word not in stop_words and i < 1000])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(df: pd.DataFrame):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    return np.array(tfidf.fit_transform([text_preprocessing(t) for t in df['text'].values]).todense())\n",
    "\n",
    "\n",
    "def vectorize(df: pd.DataFrame):\n",
    "    count_vec = CountVectorizer()\n",
    "    return np.array(count_vec.fit_transform([text_preprocessing(t) for t in df['text'].values]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models = [MultinomialNB, LogisticRegression, SVC, KNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier]\n",
    "for dataset in chosen_datasets:\n",
    "    model_trainer = ModelTrainer(dataset, \"train_preprocessing\")\n",
    "    print(f\"Start processing {dataset}\")\n",
    "    for i, model in enumerate(models):\n",
    "        model_trainer.train(model(), vectorize)\n",
    "        model_trainer.train(model(), tfidf)\n",
    "        print(f\"Processed model {i + 1}/{len(models)}\")\n",
    "    model_trainer.save_train_info_into_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "analyze_train_data(\"train_preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Исследование препроцессинга на лучшей модели SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Raw 'Accuracy': 0.864054582489543\n",
    "# Preprocessing without lemmatization 'Accuracy': 0.8566528760292869\n",
    "# Save stop words + without lemmatization 0.8605192309990312\n",
    "# Lemmatization + save stop words 0.8605192309990312\n",
    "# Only Lower text 0.8605459869746198"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "В итоге, лучше всего модель работает на обычном тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics(history, epochs=2):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs_range, acc, label='Train')\n",
    "    plt.plot(epochs_range, val_acc, label='Test')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs_range, loss, label='Train')\n",
    "    plt.plot(epochs_range, val_loss, label='Test')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_conf_matrix(labels, pred_labels):\n",
    "    cm = ConfusionMatrixDisplay(confusion_matrix(labels, pred_labels))\n",
    "    cm.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for dataset in chosen_datasets:\n",
    "    df = pd.read_csv(os.path.join(\"datasets\", dataset))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"text\"].values, df[\"label\"].values, test_size=0.25, random_state=1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "    new_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32))\n",
    "    model.add(SimpleRNN(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 3\n",
    "    history = model.fit(padded_sequences, y_train, validation_data=(new_padded_sequences, y_test), epochs=epochs)\n",
    "    print_metrics(history, epochs=epochs)\n",
    "\n",
    "    predictions = model.predict(new_padded_sequences)\n",
    "    correct = 0\n",
    "    predicted_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_label = 1 if predictions[i] > 0.5 else 0\n",
    "        predicted_labels.append(prediction_label)\n",
    "        if y_test[i] == prediction_label:\n",
    "            correct += 1\n",
    "    print_conf_matrix(y_test, predicted_labels)\n",
    "    accuracy.append(correct / len(predictions))\n",
    "    print(f\"Accuracy: {correct / len(predictions)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, predicted_labels)}\")\n",
    "    precision.append(precision_score(y_test, predicted_labels))\n",
    "    print(f\"Recall: {recall_score(y_test, predicted_labels)}\")\n",
    "    recall.append(recall_score(y_test, predicted_labels))\n",
    "print(f\"Average accuracy: {np.average(accuracy)}\")\n",
    "print(f\"Average precision: {np.average(precision)}\")\n",
    "print(f\"Average recall: {np.average(recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for dataset in chosen_datasets:\n",
    "    df = pd.read_csv(os.path.join(\"datasets\", dataset))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"text\"].values, df[\"label\"].values, test_size=0.25, random_state=1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "    new_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 5\n",
    "    history = model.fit(padded_sequences, y_train, validation_data=(new_padded_sequences, y_test), epochs=epochs)\n",
    "    print_metrics(history, epochs=epochs)\n",
    "\n",
    "    predictions = model.predict(new_padded_sequences)\n",
    "    correct = 0\n",
    "    predicted_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_label = 1 if predictions[i] > 0.5 else 0\n",
    "        predicted_labels.append(prediction_label)\n",
    "        if y_test[i] == prediction_label:\n",
    "            correct += 1\n",
    "    print_conf_matrix(y_test, predicted_labels)\n",
    "    accuracy.append(correct / len(predictions))\n",
    "    print(f\"Accuracy: {correct / len(predictions)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, predicted_labels)}\")\n",
    "    precision.append(precision_score(y_test, predicted_labels))\n",
    "    print(f\"Recall: {recall_score(y_test, predicted_labels)}\")\n",
    "    recall.append(recall_score(y_test, predicted_labels))\n",
    "print(f\"Average accuracy: {np.average(accuracy)}\")\n",
    "print(f\"Average precision: {np.average(precision)}\")\n",
    "print(f\"Average recall: {np.average(recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for dataset in chosen_datasets:\n",
    "    df = pd.read_csv(os.path.join(\"datasets\", dataset))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"text\"].values, df[\"label\"].values, test_size=0.25, random_state=1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "    new_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 5\n",
    "    history = model.fit(padded_sequences, y_train, validation_data=(new_padded_sequences, y_test), epochs=epochs)\n",
    "    print_metrics(history, epochs=epochs)\n",
    "\n",
    "    predictions = model.predict(new_padded_sequences)\n",
    "    correct = 0\n",
    "    predicted_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_label = 1 if predictions[i] > 0.5 else 0\n",
    "        predicted_labels.append(prediction_label)\n",
    "        if y_test[i] == prediction_label:\n",
    "            correct += 1\n",
    "    print_conf_matrix(y_test, predicted_labels)\n",
    "    accuracy.append(correct / len(predictions))\n",
    "    print(f\"Accuracy: {correct / len(predictions)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, predicted_labels)}\")\n",
    "    precision.append(precision_score(y_test, predicted_labels))\n",
    "    print(f\"Recall: {recall_score(y_test, predicted_labels)}\")\n",
    "    recall.append(recall_score(y_test, predicted_labels))\n",
    "print(f\"Average accuracy: {np.average(accuracy)}\")\n",
    "print(f\"Average precision: {np.average(precision)}\")\n",
    "print(f\"Average recall: {np.average(recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for dataset in chosen_datasets:\n",
    "    df = pd.read_csv(os.path.join(\"datasets\", dataset))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"text\"].values, df[\"label\"].values, test_size=0.25, random_state=1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "    new_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 3\n",
    "    history = model.fit(padded_sequences, y_train, validation_data=(new_padded_sequences, y_test), epochs=epochs)\n",
    "    print_metrics(history, epochs=epochs)\n",
    "\n",
    "    predictions = model.predict(new_padded_sequences)\n",
    "    correct = 0\n",
    "    predicted_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_label = 1 if predictions[i] > 0.5 else 0\n",
    "        predicted_labels.append(prediction_label)\n",
    "        if y_test[i] == prediction_label:\n",
    "            correct += 1\n",
    "    print_conf_matrix(y_test, predicted_labels)\n",
    "    accuracy.append(correct / len(predictions))\n",
    "    print(f\"Accuracy: {correct / len(predictions)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, predicted_labels)}\")\n",
    "    precision.append(precision_score(y_test, predicted_labels))\n",
    "    print(f\"Recall: {recall_score(y_test, predicted_labels)}\")\n",
    "    recall.append(recall_score(y_test, predicted_labels))\n",
    "print(f\"Average accuracy: {np.average(accuracy)}\")\n",
    "print(f\"Average precision: {np.average(precision)}\")\n",
    "print(f\"Average recall: {np.average(recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "    recall_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, WeightedRandomSampler\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from time import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "random.seed(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Bert(nn.Module):\n",
    "    def __init__(self, bert, bert_output_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(bert_output_dim, output_dim)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        logits = self.bert(sent_id, mask, return_dict=False)[0]\n",
    "        outputs = self.relu(logits)\n",
    "        outputs = self.fc(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    sns.set_style(style='whitegrid')\n",
    "    fig = plt.figure(figsize=(20, 14))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Accuracy', fontsize=15)\n",
    "    plt.plot(history['accuracy']['train'], label='Train')\n",
    "    plt.plot(history['accuracy']['val'], label='Test')\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('Loss', fontsize=15)\n",
    "    plt.plot(history['loss']['train'], label='Train')\n",
    "    plt.plot(history['loss']['val'], label='Test')\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr_scheduler,\n",
    "    device='cpu'\n",
    "):\n",
    "    history = defaultdict(lambda: defaultdict(list))\n",
    "    for epoch in tqdm(range(num_epochs), total=num_epochs):\n",
    "        # Train\n",
    "        start_time = time()\n",
    "        model.train(True)\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        print(f'epoch: {epoch + 1}/{num_epochs}')\n",
    "        print('Train')\n",
    "        preds, labels = np.array([], dtype=int), np.array([], dtype=int)\n",
    "        for sent_id, mask, y_batch in train_loader:\n",
    "            sent_id, mask, y_batch = sent_id.to(device), mask.to(device), y_batch.to(device)\n",
    "            outputs = model(sent_id, mask).logits.squeeze()\n",
    "            if outputs.size() == torch.Size([]):\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            loss = criterion(outputs, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += np.sum(loss.detach().cpu().numpy())\n",
    "            y_pred = nn.Sigmoid()(outputs).detach().cpu().numpy() > 0.5\n",
    "            preds = np.concatenate((preds, y_pred))\n",
    "            labels = np.concatenate((labels, y_batch.detach().cpu().numpy()))\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = accuracy_score(labels, preds)\n",
    "        train_precision = precision_score(labels, preds)\n",
    "        train_recall = recall_score(labels, preds)\n",
    "        history['loss']['train'].append(train_loss)\n",
    "        history['accuracy']['train'].append(train_accuracy)\n",
    "        history['precision']['train'].append(train_precision)\n",
    "        history['recall']['train'].append(train_recall)\n",
    "        lr_scheduler.step()\n",
    "        print('Test')\n",
    "        model.train(False)\n",
    "        preds, labels = np.array([], dtype=int), np.array([], dtype=int)\n",
    "        for sent_id, mask, y_batch in test_loader:\n",
    "            sent_id, mask, y_batch = sent_id.to(device), mask.to(device), y_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(sent_id, mask).logits.squeeze()\n",
    "                if outputs.size() == torch.Size([]):\n",
    "                    outputs = outputs.unsqueeze(0)\n",
    "                loss = criterion(outputs, y_batch.float())\n",
    "            test_loss += np.sum(loss.detach().cpu().numpy())\n",
    "            y_pred = nn.Sigmoid()(outputs).detach().cpu().numpy() > 0.5\n",
    "            preds = np.concatenate((preds, y_pred))\n",
    "            labels = np.concatenate((labels, y_batch.detach().cpu().numpy()))\n",
    "        test_loss /= len(test_loader)\n",
    "        val_accuracy = accuracy_score(labels, preds)\n",
    "        val_precision = precision_score(labels, preds)\n",
    "        val_recall = recall_score(labels, preds)\n",
    "        history['loss']['val'].append(test_loss)\n",
    "        history['accuracy']['val'].append(val_accuracy)\n",
    "        history['precision']['val'].append(val_precision)\n",
    "        history['recall']['val'].append(val_recall)\n",
    "        print(f'Epoch {epoch + 1} of {num_epochs} took {time() - start_time:.3f}s')\n",
    "        print(f'  training loss (in-iteration): \\t{train_loss:.6f}')\n",
    "        print(f'  validation loss (in-iteration): \\t{test_loss:.6f}')\n",
    "        print(f'\\n  training accuracy: \\t\\t\\t{train_accuracy * 100:.2f} %')\n",
    "        print(f'  validation accuracy: \\t\\t\\t{val_accuracy * 100:.2f} %')\n",
    "        print(f'\\n  training precision: \\t\\t\\t{train_precision * 100:.2f} %')\n",
    "        print(f'  validation precision: \\t\\t{val_precision * 100:.2f} %')\n",
    "        print(f'\\n  training recall: \\t\\t\\t{train_recall * 100:.2f} %')\n",
    "        print(f'  validation recall: \\t\\t\\t{val_recall * 100:.2f} %')\n",
    "        if epoch > 0:\n",
    "            plot_learning_curves(history)\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def predict(model, test_batch_gen, device='cpu'):\n",
    "    res_outputs = np.array([])\n",
    "    res_targets = np.array([])\n",
    "    for batch in test_batch_gen:\n",
    "        input_ids, attention_mask, target = batch\n",
    "        input_ids, attention_mask, target = input_ids.to(device), \\\n",
    "                                            attention_mask.to(device), \\\n",
    "                                            target.to(device)\n",
    "        output = model(input_ids, attention_mask).logits.squeeze()\n",
    "        output = nn.Sigmoid()(output) > 0.5\n",
    "        res_outputs = np.append(res_outputs,\n",
    "                                output.detach().cpu().numpy())\n",
    "        res_targets = np.append(res_targets,\n",
    "                                target.view(-1, 1).cpu().numpy())\n",
    "\n",
    "    print(f'accuracy_score: {accuracy_score(res_targets, res_outputs)}')\n",
    "    print(f'precision_score: {precision_score(res_targets, res_outputs)}')\n",
    "    print(f'recall_score: {recall_score(res_targets, res_outputs)}')\n",
    "    print('confusion matrix')\n",
    "    print(print_conf_matrix(res_targets, res_outputs))\n",
    "    return accuracy_score(res_targets, res_outputs), precision_score(res_targets, res_outputs), recall_score(res_targets, res_outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for dataset in chosen_datasets:\n",
    "    df = pd.read_csv(os.path.join(\"datasets\", dataset))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\", use_fast=False)\n",
    "    bert = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", output_attentions=False, output_hidden_states=False)\n",
    "    # model = Bert(bert, bert.classifier.out_features, 1)\n",
    "    bert.classifier = nn.Linear(in_features=768, out_features=1, bias=True)\n",
    "    model = bert\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"text\"].values, df[\"label\"].values, test_size=0.25, random_state=1)\n",
    "\n",
    "    max_seq_len = 256\n",
    "    tokens_train = tokenizer.batch_encode_plus(\n",
    "        X_train,\n",
    "        max_length = max_seq_len,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    tokens_test = tokenizer.batch_encode_plus(\n",
    "        X_test,\n",
    "        max_length = max_seq_len,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "    train_y = torch.tensor(y_train)\n",
    "\n",
    "    test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "    test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "    test_y = torch.tensor(y_test)\n",
    "\n",
    "    batch_size = 16\n",
    "    train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "    train_labels, train_counts = np.unique(y_train, return_counts=True)\n",
    "    train_class_weights = [sum(train_counts) / c for c in train_counts]\n",
    "    train_weigths = [train_class_weights[e] for e in y_train]\n",
    "    train_sampler = WeightedRandomSampler(weights=train_weigths, num_samples=y_train.shape[0])\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "    test_sampler = RandomSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "\n",
    "    output_dim = 1\n",
    "    lr = 3e-5\n",
    "    num_epochs = 3\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.2)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer,\n",
    "                                                    gamma=0.9, verbose=True)\n",
    "    model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    num_epochs,\n",
    "    lr_scheduler,\n",
    "    device\n",
    "    )\n",
    "    acc, prec, rec = predict(model, test_dataloader, device)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Average accuracy: {np.average(accuracy)}\")\n",
    "print(f\"Average precision: {np.average(precision)}\")\n",
    "print(f\"Average recall: {np.average(recall)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
